---
title: "rrq: design"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{rrq}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Overall design

There are many process-level parallelism interfaces for R. `rrq` attempts to present an interface that differs from most in the level of control it gives the user and the focus on non-blocking interactions but explicit control.

### Background

For years, the `parallel` package has provided users with the ability to run tasks in parallel with very little setup. Given a list of data `x` and some function `f`, one can change from the serial code

```r
lapply(x, fun)
```

to run in parallel given a cluster object `cl`

```r
parallel::parLapply(cl, x, fun)
```

(the even simpler `parallel::mclapply(x, fun)` can be used on platforms other than Windows with reasonable success). Nice as this is it suffers some drawbacks, most of which follow from the derive from the simple blocking interface:

* The R session is blocked while the calculations run, even though the host session is doing (essentially) nothing
* The number of workers (size of the cluster) is fixed at the point where `parLapply` has been called, and is restricted to a single node without considerable effort. One cannot add workers to the cluster while it runs, or remove unneeded ones as tasks finish.
* It is not possible to retrieve partially completed results - we have to wait for all the tasks to complete before working with any
* If tasks are of uneven size, the load balancing form (`parallel::parLapplyLB`) is quite slow

As such it is hard to build intefaces like queues or work through dependency graphs (though see heroic work in [future](https://future.futureverse.org/) and [targets](https://docs.ropensci.org/targets/)). Attempts at doing this run into issues of where do you store the data and the queue in such a way that you can safely have multiple worker processes interacting with the queue without corrupting the database or hitting race conditions. Approaches like [liteq](https://cran.r-project.org/package=liteq) may not work on network file systems, and therefore become limited to a single node.

At the other end of the scale, HPC systems with their schedulers can avoid all these issues, but with byzantine interfaces and slow per-task submission.

### rrq

* Uses [Redis](https://redis.io) as a task broker; this provides a database to hold tasks that allows very fast network based access to many processes
* Uses a non-blocking design where control is returned to the controller process as immediately while tasks run in the background
* Supports a scalable worker pool; no workers are needed for tasks to be queued, and workers can be added or removed at will while tasks are running
* Allows for multiple non-interacting queues, multiple priority levels within a queue, and automatically resolved dependencies among completing tasks
* Supports a fully load-balanced design with overheads of around 1ms per task
* Supports optionally running each task in a separate process, allowing for strong isolation between tasks as well as per-task timeouts and cancellability
* Allows rich querying of task status and progress and worker history
* Exposes both low-level primatives for working with individual tasks as well as higher level interfaces that mimic functions like `lapply`
